---
title             : "childes-db: a flexible and reproducible interface to the Child Language Data Exchange System"
shorttitle        : "childes-db: an interface to CHILDES"

author: 
  - name          : "Alessandro Sanchez*"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, 450 Serra Mall, Stanford, CA 94305"
    email         : "sanchez7@stanford.edu"
  - name          : "Stephan Meylan*"
    affiliation   : "2"
  - name          : "Mika Braginsky"
    affiliation   : "3"
  - name          : "Kyle E. MacDonald"
    affiliation   : "1"
  - name          : "Daniel Yurovsky"
    affiliation   : "4"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"
  - id            : "2"
    institution   : "University of California, Berkeley"
  - id            : "3"
    institution   : "MIT"
  - id            : "4"
    institution   : "University of Chicago"

author_note: |
  Thanks to Brian MacWhinney for advice and guidance, and to Melissa Kline for her work on ClanToR, which formed a starting point for our work. This work is supported by a Jacobs Advanced Research Fellowship to MCF.

abstract: |
  The Child Language Data Exchange System (CHILDES) has played a critical role in research on child language development. However, traditional methods of inquiry into the data have often relied on a command line interface to extract developmental indices or custom parsers to extract data for computational modeling. Now, advances in open-source software allow for novel approaches in working with this dataset. We introduce childes-db, a database-formatted mirror of CHILDES that improves data accessibility and usability by offering novel interfaces, including browsable web applications and an R application programming interface (API).  Along with a versioned infrastructure that facilitates reproduction of past analyses, these interfaces lower barriers to analyzing naturalistic parent-child language, allowing for a wider range of researchers in language and cognitive development to easily leverage CHILDES in their work. 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["childesdb.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, echo = FALSE, warning=FALSE}
library(papaja)
library(tidyverse)
library(childesr)
library(directlabels)
library(koRpus)
library(png)
library(here)
knitr::opts_chunk$set(cache = TRUE, echo = FALSE)
```

# Introduction

Children's language acquisition is a core puzzle in cognitive science. How are the representations underlying the generative use of language learned over children's first years? Because a language is comprised of many individual pieces of information -- the names of particular objects, the marker for the past tense, the position of determiners -- language development is fundamentally a question of learning from environmental input, which is the only source of information on these specifics. Further, children are often reluctant experimental participants; often their most revealing and most sophisticated uses of language emerge in naturalistic play. Thus, language acquisition research must be grounded in the ecological behavior of children, both their language input and their language production in context. 

The foundational resource for studies of language acquisition is recordings and transcripts of children. Starting with Roger Brown's [-@brown1973] work on Adam, Eve, and Sarah, longitudinal recordings of children's talk (and the talk they hear from their caregivers) have formed the basis for this field. But creating individual transcripts is extremely hard work. Beyond gathering the data, even orthographic transcriptions (without phonetic detail) can take ten times the length of the original recording to transcribe. Thus, researchers' desire for data from multiple ages or multiple children can very quickly outstrip their resources. 

Established in 1984 to address this issue, the Child Language Data Exchange System (CHILDES) aims to make transcripts and recording of children's language available for researchers via a free resource [@macwhinney2000]. CHILDES archives tens of thousands of transcripts of children’s speech, making it a critical resource for characterizing children’s early productive language use as well as their language environment. As the first major effort to consolidate and share transcripts of child language, CHILDES has been a pioneer in the move to curate and disseminate large-scale behavioral datasets publicly. 

Since its inception, a tremendous corpus of research has made use of CHILDES data. Individual studies are too numerous to list, but  classics include studies of morphological over-regularization [@marcus1992], distributional learning [@redington1998], word segmentation [@goldwater2009], the role of frequency in word learning [@goodman2008] and many others. Some studies analyze individual examples in depth [e.g., @snyder2007] while others work with the corpus as a whole [e.g., @meylan2017]. These are just a few of the thousands of studies that take CHILDES corpora -- transcripts, annotations, and associated media -- as starting points. 

Yet there are some challenges working with CHILDES, both for students and for advanced users. The CHILDES ecosystem uses a special file format (CHAT), which is stored in a plain text format but includes structured annotations grouped into tiers (stored on separate lines) so that information about utterances can be stored with accompanying information such as the phonological or morphological structure of the utterance. These files are analyzed using a command-line tool (CLAN) with a host of specific arguments that allow users to count word frequencies, compute statistics (e.g., mean length of utterance, or MLU). While this system is flexible and powerful, mastering the CHAT codes and the CLAN tool can be daunting to navigate for a beginner or student. These technical barriers decrease the ease of casual exploration by a novice researcher or in a classroom exercise.

On the opposite end of the spectrum, for data-oriented researchers who are interested in doing large-scale analyses of CHILDES, the current tools are also not ideal. CLAN software is an excellent tool for interactive exploration, but -- as a free-standing application -- can be tricky to build into a processing pipeline written in a modern analytic platform such as Python or R. Thus, researchers who would like to ingest the entire corpus (or some large subset) into a computational analysis typically write their own parsers of the CHAT format to extract the subset of the data they would like to use [e.g., @redington1998;@yang2013;@meylan2017]. 

This practice is problematic for a number of reasons. Effort is wasted in rewriting the same parser again and again. In addition, this process introduces a major source of errors and inconsistencies in data handling due to difficulties dealing with the many special cases in the CHAT standard. Further, these scripts are rarely shared, leading to much greater difficulty in reproducing the exact numerical results from papers using CHILDES [see e.g., @meylan2017]. This lack of computational reproducibility is widely recognized as problematic because it does not allow researchers to verify or build on published research [@donoho2010;@stodden2016]. Finally, the CHILDES corpus itself is a moving target;  computational work using the entire corpus at one time point may include a different set of data than subsequent work (due to new contributions or revisions). 

In the current manuscript, we describe a system for extending the functionality of CHILDES to address these issues. Our system, childes-db, is a database-formatted mirror of CHILDES that allows programmatic access through an application programming interface (API). This infrastructure allows the creation of web applications for browsing and visualizing the data easily, facilitating classroom use of the dataset. Further, it can be accessed programmatically by advanced researchers, obviating the need to write one-off parsers of the CHAT format. The database is versioned for access to previous images, allowing computational reproducibility of particular analyses.

We begin by describing the architecture of childes-db and the web applications that we provide. We next describe the `childesr` API, which allows for programmatic access to the data. We then present two worked examples of specific uses of the system using both the web app and the API. The first examines the frequency of color words in children's input; the second quantifies the growth of lexical diversity across genders. We end by presenting some suggestions for the use of the childes-db web frontend in classroom teaching. 

# Design and technical approach

<!-- Remind readers why they're reading this: understanding the structure helps you use and understand the tools -->

<!-- We first present the design and technical approach of childes-db, then describe the interactive analysis tools provided by our web-based frontend.  -->

## Database format

Unlike the *parsing* approach in CLAN which entails the sequential processing of strings, childes-db treats CHILDES as a set of linked tables, with records corresponding to intuitive abstractions such as words, utterances, and transcripts. Users of data analysis languages like R or Julia, libraries like Pandas, or those familiar with Structured Query Language (SQL) will be familiar with operations on tables such as filtering (subsetting), sorting, aggregation (grouping), and joins (merges). Although we expect most users to interact with the database through the `childesr` API for the `R` language described below, we begin with a top-level description and motivation for the design of the database schema, details of the database’s current technical implementation, and our versioning scheme.

At its core, childes-db is a database consisting of a set of linked tabular data stores where rows correspond to records. <!-- what did you mean here? don't rows = records--> The smallest unit of abstraction tracked by the database is a token, treated here as the citation orthographic form of a word. Using the standardized written form of the word facilitates the computation of lexical frequency statistics, for comparison or aggregation across children or time periods. Deviations from the citation form -- reflecting the deviations from citation forms that are particularly common in the course of language development -- are kept as a separate (possibly null) field associated with each token.

Other tables in the database comprise a hierarchical system of collections built on top of tokens -- *utterance*, *transcription*, *corpus*, and *collection* -- which stores attributes appropriate for each level of description. Every entity includes attributes that link it to all higher-order collections, e.g., an utterance lists the transcript, corpus, and collection to which it belongs.  An *utterance* contains one or more words and includes fields such as the utterance type (declarative, question, etc.), total number of tokens, and the total number of morphemes (if the morphological structure is available in the original CHAT). 

A *transcription* consists of one or more utterances and includes the date collected, the name of the target child, and age in days (if defined), and the filename from CHILDES. A *corpus* consists of one or more transcripts, corresponding to well-known collections like the Brown or Providence corpus. Finally, a *collection* is a superordinate collection of corpora generally corresponding to a geographic region, following the convention in CHILDES. Because every entity can be linked to a top-level collection, childes-db places content from all languages in the same table for a given level of abstraction <!-- a little confused by this last sentence -->.

We chose to treat participants separate from the above hierarchy because children can occur across transcripts (e.g., the Brown Corpus). A participant is associated with every word and utterance, including a name, role, 3-letter CHILDES identifier (CHI, MOT, FAT, etc.), and the range of ages (or age of corresponding child) for which they are observed. For non-child participants, the record contains an identifier for the target child to associate caregivers and children.

## Technical implementation

The above tabular datastore is implemented as a MySQL database. As an industry-standard, open-source relational database server, the above database can be accessed directly from a wide range of programming languages. The childes-db project provides hosted read-only databases for direct access and for `childesr` (described below) as well as compressed .sql exports for local installation. While the former is appropriate for most users, local installation can provide performance gains (allowing a user to access the database on their local machine or on their network) as well as allowing users to store derived information in the same database.

In order to import the CHILDES corpora into the MySQL schema described above, it must first be accurately parsed and subsequently vetted to ensure the integrity of the data migration. Along with being made available in CHAT, the corpora are also downloadable in a format known as eXtensible Markup Language, or XML; this significantly mitigated any problems related to parsing CHAT as it allowed us to leverage the built-in XML parsing libraries available in numerous programming languages such as Python. Once the XML data were crawled and parsed into tokens and utterances, they were imported into a MySQL database. The meticulously constructed CHILDES XML Schema allowed us to make precise decisions as to what information we found relevant to our database and what was to be discarded or ignored; further information on what data were retained can be found below.

The data imported into childes-db requires extensive data integrity checks to ensure that our parse of the corpora is accurate and preferable over the adhoc parsers developed by many individual researchers. In order to evaluate this, we compared unigram counts in our database with those outputted by CLAN, the command-line tool built specifically for analysis of transcripts coded in CHAT. <!-- technically this is all we do right now -->

<!-- [[Details of testing: Why trust our parse over your in-house library? CLAN TESTING DETAILS - also mention versioning as a reason to trust]] -->

### Versioning

<!-- Continue to make the case that it's important to version! childes changes without warning, corpora get added, etc. -->

The content of CHILDES changes as additional corpora are added or transcriptions are updated; currently, these changes are not systematically tracked.
Here we introduce a simple versioning system by proucing a new complete parse of the current state of CHILDES every 6 months.
Users interact with the most recent version of the database available by default. 
To support reproduction of results with previous versions of the database, we continue to host recent versions (up to the last 6 versions) through our `childesr` API so that researchers can run analyses against specific versions of the database.
<!-- Potentially put some R code to show easy it is to access previous versions? -->
For versions more than three years old, users have the options of downloading compressed .sql files and serving them with a local installation of MySQL server.
<!-- How easy is it to implement versioning in the Shiny apps?-->

### Current Annotation Coverage

The current implementation of childes-db emphasizes the computation of lexical statistics, and consequently focuses on reproducing the words, utterances, and speaker information in CHILDES.
We have yet to parse and make available the following information:

- Sparsely annotated tiers, e.g. phonology (`%pho`) and situation (`%sit`)
- Media links, including timing information <!-- we have media timestamps -->
- compound word markers, indicated with underscores ("green_eggs_and_ham") <!-- we have this -->
- Tone direction and stress
- Filled pauses 
- Reformulations, word revision, and phrase revision, e.g. <what did you> [//] how can you see it ?
- paralinguistic material, e.g. [=! cries]

We will prioritize the addition of these additional information sources in response to community feedback;
extending coverage to the above information sources will not require changes to the existing database schema.

# Interfaces for Accessing childes-db

We first discuss the childes-db web apps and then introduce the `childesr` package.

## Interactive Analysis Tools

<!-- need a good shorthand for the interactive analysis tools: web apps -->

childes-db offers a collection of browser-based interactive visualizations that enable data exploration through easy-to-use interfaces that do not require any programming knowledge. These tools are intended for casual users who seek to extract useful developmental indices from CHILDES without any technical overhead. The visualizations available through childes-db are the following: Frequency Counts (lexical statistics), Derived Measures (lexical diversity), and Population Viewer (corpora statistics). All three of these visualizations were built using Shiny, an R package that enables easy building of web applications in R. For each visualization, a user specifies a subset of the data (in particular the collection, corpus, child, and speaker) and is also able to restrict the age range of the child with slider bars. Any number of corpora, children, or speakers may be selected for analysis, allowing for aggregate counts across a whole range of data in the CHILDES system, a task that could not have been easily done using previous methods. Along with the visualizations, childes-db makes the raw data itself available for download under a separate “Table” tab; this allows researchers to further explore the underlying data from the plots.

### Frequency Counts

<!-- sm: intro sentence here for the role of frequency in CLA research  --> 
The Frequency Counts app allows users to enter a word (or words) in a text box and see the frequency (in parts per million) in which this word was uttered across a child's age for a particular subset of the data, whether it is an individual child in the Brown corpus or all Spanish speaking children and their mothers. <!-- sm: "whether..." is awk.  -->
The ability to view the caregiver’s usage of a term alongside a child’s assists researchers in better understanding the relationship between input and uptake. Users can also plot word trajectories alongside each other (such as “mom” and “dad” or “front” and “back”) for convenient cross-word comparisons.

### Derived Measures

<!-- sm: intro sentence here for the role of developmental metrics in CLA research and in downstream applications like SLP--> 
There are a number of ways to measure the lexical diversity of an individual's productive speech. <!-- sm: different intro; MLU isn't a lexical diversity measure -->
Some of these measures, including MLU-w (mean length of utterance in words), TTR (type-token ratio), MTLD (measure of textual lexical diversity), and voc-d are available in the Derived Measures app, which plots these measures across age for a given subset of data, again specified by collection, corpora, children, and speakers. <!-- sm: MLU is not a measure of lexical diversity-->
Because of the underlying gaps in available CHILDES morphological data, MLU-w is computed and not MLU-m (mean length of utterance in morphemes). <!-- sm: I think we should go ahead and compute this for transcript with MOR tiers? Given that this was one of the first uses, I don't think Brian will like the 'underlying gaps' explanation-->
In the English language, these two measures have been shown to be highly correlated. <!-- sm: citation needed -->
As with the Frequency Counts app, caregiver’s lexical diversity measures can be plotted alongside those of children. 

### Population Viewer

The population viewer is a tool that helps users understand the relative sizes and temporal extents of various corpora by displaying the total number of utterances or tokens in the available corpora at particular ages. In many instances the size of a given corpus may inform researchers’ decisions as to what is the best target dataset for analysis. <!-- note that the graphs don't currently include a grouping factor, so adding multiple corpora generates one line, so you can't actually compare two corpora in the same visualization -->


## The `childesr` Package

Although the interactive analysis tools described above cover some of the most common use cases of CHILDES data, researchers interested in more detailed and flexible analyses will want to interface directly with the data in childes-db. Making use of the `R` programming language [@R-base], we provide the `childesr` package to help researchers accomplish this task. `R` is an open-source, extensible statistical computing environment that is rapidly growing in popularity across fields and is increasing in use in child language research [e.g. @song2015; @norrman2015]. The `childesr` package abstracts away the details of connecting to <!-- sm: and querying-->  the database. Users can take advantage of the tools developed in the popular `dplyr` package [@R-dplyr], which make manipulating large datasets quick and easy. We describe the commands that the package provides and then give several worked examples of using the package for analyses.

The `childesr` package is easily installed via CRAN, the comprehensive R archive network. To install, simply type: `install.packages("childesr")`. After installation, users have access to data loading functions that retrieve a variety of subsets <!-- sm: entities? variety of subsets sounds non-hierarchical-->  of the data:

- `get_collections()` gives the names of available collections of corpora ("Eng-NA", "Spanish", etc.)
- `get_corpora()` gives the names of available corpora ("Brown", "Clark", etc.)
- `get_transcripts()` gives information on available transcripts (language, date, target child demographics)
- `get_participants()` gives information on transcript participants (name, role, demographics)
- `get_speaker_statistics()` gives summary statistics for each participant in each transcript (number of utterances, number of types, number of tokens, mean length of utterance)
- `get_utterances()` gives information on each utterance (glosses, stems, parts of speech, utterance type, number of tokens, number of morphemes, speaker information, target child information)
- `get_types()` gives information on each type within each transcript (gloss, count, speaker information, target child information)
- `get_tokens()` gives information on each token (gloss, stem, part of speech, number of morphemes, speaker information, target child information)

Each of these functions can be supplied with arguments that restrict the query to a particular subset of the data (e.g. by collection, by corpus, by speaker role, by target child age, etc.) For more detailed documentation, see the package repository (http://github.com/langcog/childesr).


# Using childes-db: Worked Examples

In this section we give a number of examples of how childes-db can be used in both research and teaching, using both the web apps and the R API.

## Research applications 

### Color frequency 

One common use of the CHILDES corpora is estimating the frequency with which children hear different words. These frequency estimates are used both in the development of theory [e.g. frequent words are learned earlier; @goodman2008], and in the construction of age-appropriate experimental stimuli. One benefit of the childes-db interface is that it allows for easy analysis of how the frequencies of words change over development. Many of our theories in which children learn the structure of language from its statistical properties implicitly assume that these statistics are *stationary*, i.e. unchanging over development [e.g., @saffran1996]. However a number of recent analyses show that the frequencies with which infants encounter both linguistic and visual properties of their environment may change dramatically over development [@fausey2016], and these changing distributions may produce similarly dramatic changes in the ease or difficulty with which these regularities can be learned [@elman1993].

To demonstrate how one might discover such a non-stationary, we take as a case study the frequency with which children hear the color words of English (e.g. "blue", "green"). Color words tend to be learned relatively late by children, potentially in part due to the abstractness of the meanings to which they refer [see @wagner2013]. However, within the set of color words, the frequency with which these words are heard predicts a significant fraction of the variance in their order of acquisition [@yurovsky2015]. But are these frequencies stationary -- e.g. do children hear "blue" as often at 12 months as they do at 24 months? We answer this question in two ways -- first using the web apps, and then using the `childesr` package.

#### Using web apps

To investigate whether the frequency of color words is stationary over development, a user can navigate to the Frequency app, and enter a set of color words into the `Word` selector separated by a comma: here "blue, red, green." Because the question of interest is about the frequency of words in the input (rather than produced by children), the `Speaker` field can be set to reflect this. In this example we select "Mother" because, across corpora in CHILDES, the speaker tagged with the Mother role tends to produce most of the words that children hear. Because children learn most of their basic color words by the age of 5, the age range of 1-5 years is a reasonable choice for `Ages to include`. The results of these selections are shown in Figure \ref{fig:color-shiny}. We can also create a hyperlink to store these set of choices so that we can share these results with others, or with ourselves in the future, by clicking on the `Bookmark` button in the bottom left corner.

From this figure, it seems likely that children hear "blue" more frequently early in development, but the trajectories of the "red" and "green" are less clear. We also do not have a good sense of the errors of these measurements, are limited to just a few colors at a time before the plot becomes too busy, and cannot combine frequencies across speakers. To perform this analysis in a more compelling and complete way, a user can use the `childesr` interface to get more direct access to the CHILDES corpora. 

```{r color-shiny, out.width = "500px", fig.cap = "An example of using the Frequency shiny app to explore how children's color input changes over development"}
knitr::include_graphics("images/color-shiny.png")
```

#### Using childesr

We can analyze these learning trajectories using childesr by braking the process into five steps: (1) define our words of interest, (2) find the frequencies with with which children hear these words, (3) Find the proportion of the *total words* children hear that these frequencies account for, (4) Aggregate across transcripts and children to determine the error in our estimates of these proportions, and (5) plot the results.

For this analysis, we will define our words of interest as the basic color words of English (except for gray, which children hear very rarely). We store these in the `colors` variable, and then use the `get_types` function from `childesr` to get the type frequency of each of these words in all of the corpora in CHILDES. For demonstration, we look only at the types produced by the speakers in each corpus oftagged as Mother and Father. We also restrict ourselves to children from 1-5 years old (12 to 60 months), and look only the American English corpora.

```{r define-colors, echo = TRUE}
colors <- c("black", "white", "red", "green", "yellow", "blue", "brown", 
             "orange", "pink", "purple")

color_counts <- get_types(collection = "Eng-NA", role = c("Mother", "Father"),
                          age = c(12,60), type = colors)
```


```{r graph-colors}
graph_colors <- data_frame(color = colors,
                           graph_color = if_else(color == "white", 
                                                 "light gray", color))

```

To normalize correctly (i.e. to ask what proprotion of the input children hear consists of these color words), we need to know how many total words these children hear from their parents in these transcripts. To do this, we use the `get_speaker_statistics` function, which will return a total number of tokens (`num_tokens`) for each of these speakers.

```{r get-token-frequencies, echo = TRUE}
# Get the ids corresponding to all of the speakers we are interested in
parent_ids <- color_counts %>%
  distinct(collection_id, corpus_id, transcript_id, speaker_id) 

# Find in the total number of tokens produced by these speakers
parents <- parent_ids %>%
  left_join(get_speaker_statistics(collection = "Eng-NA")) %>%
  select(collection_id, corpus_id, transcript_id, speaker_id, num_tokens)
```

We now join these two pieces of information together--how many times each speaker produced each color word, and how many total words they produced. We then group the data into 6-month age bins, and compute the proportion of tokens that comprise each color for each child in each 6-month bin. For comparability with the web app analysis, we convert the proportions to parts per million words
```{r join-colors-and-tokens, echo = TRUE}
count_estimates <- color_counts %>%
  left_join(parents) %>%
  mutate(age_months = target_child_age / 30.5,
         age_bin = as.integer(floor(age_months / 6) * 6),
         color = tolower(gloss)) %>%
  group_by(age_bin, color, target_child_id, transcript_id) %>%
  summarise(count = sum(count), num_tokens = sum(num_tokens)) %>%
  summarise(count = sum(count), num_tokens = sum(num_tokens)) %>%
  mutate(parts = count / num_tokens * 1e6)
```

Finally, we use non-parametric bootstrapping to estimate 95% confidence intervals for our estimates of the parts per million words of each color term with the `tidyboot` package.

```{r computer-color-error, echo = TRUE}
count_estimates_with_error <- count_estimates %>%  
  tidyboot::tidyboot_mean(parts) %>%
  left_join(graph_colors) %>%
  mutate(color = factor(color, levels = colors))
```

Figure \ref{fig:color-plot} shows the results of these analyses: Input frequency varies significantly over the 1-5 year range for nearly every color word.

```{r color-plot, fig.height = 5, fig.width = 10, fig.cap ="Color frequency as a function of age. Points represent means across transcripts, error bars represent 95% confidence intervals computed by nonparametric bootstrap", cache = TRUE, message = FALSE, warning = FALSE}
ggplot(count_estimates_with_error, aes(x = age_bin, y = empirical_stat, 
                            ymin = ci_lower, ymax = ci_upper,
                            color = color, label = color)) + 
  geom_pointrange(position = position_dodge(.5)) + 
  geom_point() +
  geom_smooth(method = "loess", se = F, span = .5) +
  facet_wrap(~ color, scales = "free_y") + 
  theme_classic(base_size = 14) +
  scale_color_manual(values = graph_colors$graph_color) +
  scale_x_continuous(breaks = seq(12, 60, 12),
                     name = "Age (months)") + 
  scale_y_continuous(name = "Frequency (per million words)") +
  geom_dl(method = list(dl.trans(x=x +.2), "last.qp", cex=1)) + 
  theme(legend.position = "none")
```


### Gender
```{r}
stats <- get_speaker_statistics(role = "Target_Child")
```

```{r warning=FALSE}
lang_threshold <- 575
age_max <- 4

lang_counts <- stats %>% 
  filter(target_child_age < age_max * 365) %>%
  group_by(language) %>%
  
  
  summarise(n = n())

included_languages <- filter(lang_counts, n > lang_threshold)$language

data <- stats %>%
  filter(!is.na(target_child_sex), 
         language %in% included_languages) %>%
  group_by(target_child_id, target_child_age, target_child_sex, language) %>%
  filter(mtld != 0) %>%
  summarise(measure = mean(mtld)) %>%
  ungroup() %>%
  mutate(age_years = target_child_age / 365, 
         target_child_sex = factor(target_child_sex, levels = c("male","female"))) %>%
  filter(age_years < age_max)

mod <- lme4::lmer(measure ~ target_child_sex * poly(age_years, 2) - 1 + 
                    (1 | target_child_id) +
                    (target_child_sex + age_years | language), 
  data = data)

mod_data <- expand.grid(age_years = seq(0,age_max, .1), 
                                          target_child_sex = c("male","female"),
                                          language = included_languages) %>%
  as_data_frame()

mod_data$measure <- predict(mod, newdata = mod_data, 
                           re.form = ~(target_child_sex + age_years | language)) 

ggplot(data, aes(x = age_years, y = measure, 
                 color = target_child_sex)) +
  geom_point(alpha = .3) + 
  geom_line(data = mod_data, 
            aes(x = age_years, y = measure, color = target_child_sex)) +
  # geom_smooth(span = 1, method = "loess") + 
  facet_wrap(~language) + 
  ggthemes::theme_few() + 
  ggthemes::scale_color_ptol(name = "Sex") + 
  xlim(0,age_max) + 
  ylim(0,15) + 
  xlab("Age (years)") + 
  ylab("MTLD") + 
  theme(legend.position = "bottom")
```

## Teaching with childes-db

### In class demonstrations

Teachers of courses on early language acquisition often want to demonstrate interesting changes in children’s early language. One method is to present static displays that show text from parent-child conversations extracted from CHILDES or data visualizations of various metrics of production and input (e.g., MLU or Frequency). The challenge with static displays is that they cannot be modified during a lecture and thus rely on the instructor selecting examples that will be compelling to students. 

In-class demonstrations offer a solution and can be a powerful way to explain complex concepts while increasing student engagement with the course materials. One goal of creating the web applications in childes-db is to give instructors a new tool for illustrating concepts in children's language acquisition. 

For example, a teacher could want to show the types of words that children first produce. Diary studies and large-scale studies using parent report show that children’s first words tend to fall into a fairly small number of categories: people, food, body parts, clothing, animals, vehicles, toys, household objects, routines, and activities or states [@clark2009first; @fenson1994variability]. The key insight is that young children talk about what is going on around them: people they see every day, e.g., toys and small household objects they can manipulate or food they can control.

A teacher could illustrate children's early vocabularies by showing a table with columns for the lexical category, examples of words from that category, and children's average age of production. To make this interactive using the web apps, the teacher could:

1. introduce the research question (e.g., What are the types of words that children first produce?)
2. allow students to reflect or do a pair-and-share discussion with their neighbor
3. show the trajectory of a single lexical item while explaining key parts of the visualization (see Panel A of Figure \ref{fig:in-class-demo-plot})
4. elicit hypotheses from students about the kinds of words that children are likely to produce 
5. make real-time queries to the web application to add students' suggestions and talk through the updated plots (Panels B and C of Figure \ref{fig:in-class-demo-plot})
6. finish by entering a pre-selected set of words that communicate the important takeaway point (Panel D of Figure \ref{fig:in-class-demo-plot}) 

```{r in-class-demo-plot, fig.pos="h", out.width = "95%", fig.cap="Worked example of using the web applications for in-class teaching. Panels A-D show how an instructor could dynamically build a plot during a lecture to demonstrate a key concept in language acquisition."}

png::readPNG(here::here("imgs/in_class_teach_viz.png")) %>% grid::grid.raster()
```

In addition to the web applications, instructors can use childes-db to download the raw data used to generate the figures. This gives students the opportunity to further explore and analyze the data they see in the plots. Moreover, this functionality provides an example of a second way that childes-db can facilitate language acquisition courses by making data easily-accessible for tutorials and student research projects. 

### Tutorials and programming assignments

One of the goals for courses on applied natural language processing (NLP) is for students to get hands-on experience using NLP tools to analyze real-world language data. A primary challenge for the instructor is to decide how much time should be spent teaching the requisite programming skills for accessing and formatting language data, which are typically unstructured. One pedagogical strategy is to abstract away these details and avoid having students deal with obtaining data and formatting text. This approach shifts students' effort away from data cleaning and towards programming analyses that encourage the exploration and testing of interesting hypotheses.

One goal of childes-db and `childesr` API is to provide instructors with an easy-to-learn method for giving students programmatic access to child language data. The aim is to reduce time spent getting data out of CHILDES and allow more course time for thinking about interesting questions that could be answered with NLP and child language data. Moreover, by writing our API in the R programming language, students will gain access to a general workflow can be integrated into an analysis pipeline that includes state of the art NLP tools.

For example, an instructor could create a programming assignment with the goal of reproducing the key findings in the case studies presented above -- color words or gender. Depending on the students' knowledge of R, the instructor could decide how much of the `childesr` starter code to provide before asking students to generate their own plots and writeups. Moreover, the instructor could take advantage of recent advances in tools for teaching literate programming such as R Markdown [@xie2015dynamic], building in pre-written blocks of executable code that demonstrate key programming concepts for students and including incomplete or blank code blocks that students can use to write their own code.

# Conclusion

<!-- reiterate importance -->

<!-- adding more tiers is a goal for the future -->

# References
```{r create_r-references}
r_refs(file = "childesdb.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
